---
title: live_media_video
date: 2021-02-18 02:44:49
tags: video
categories: video
---

### 图像科技发展史：
#### 图像的本质：
图像的本质可以说是反射光的集合，不同的物质分子组成等不同，那么光照射到物质上，有部分频率的光被吸收，剩下的反射出来，就形成不同的<!--more-->
颜色，反映了物质的基本特征；可以说每个像素点是一维值，就像声音的采样值；但图片还有大小位置，等信息；所以以一个方图为例，有图片的x轴
大小，y轴大小，甚至z轴空间信息，反映出来就是光影形成的三维效果；另外还有物体的位置；
而声音其实也有这些信息，声音的位置，不同物体的振动不同，在空气中振动的大小等；只是声音这些信息不能像图像一样能被人更好的利用；
或者说信息含量比较小；所以自然界中动物不止出现听觉还有视觉；
图像作为这种波动类型的物理信号的特点和表示：振幅，频率，相位，波长，共振等等，这些不赘述，有兴趣再翻阅资料；


#### 图像的记录发展史：
           图像最开始只能通过绘画记录下来，直到后来，人们发现了透镜成像原理和感光物质显像原理，即时记录图像的工具-相机才慢慢被开发出来；
+ 简单来说，图像的记录经历了一下的时代:  
图像-<->湿版摄影法： 即通过成像后，一些感光的化学物质记录，形成图像
图像<--> 胶卷相机时代：即：图像反射光->小孔成像->感光物质曝光底片->冲洗照片
图像<-->数字信号和处理时代：即图像反射光-->光敏电阻(单色)-->电信号-->模数转换-->101010的数字信号-->  像素值->计算机处理-->屏幕呈现
PS:https://zhuanlan.zhihu.com/p/161200077

#### 图像基本入门：
{% asset_img basic.png This is an example image %}
图像由像素点构成，简称像素(Pixel:picture Element）：像素是图像显示的基本单位，通常说一幅图片的大小，例如是1920*1080，即长度为1920个像素点，宽度为1080个像素点，乘积为2,073,600，即这个图片是两百万像素的，拍照中常说的也是这个；
PPI: 分辨率也是显示器的重要指标，而PPI是Pixels Per Inch，即每英寸像素；即手机或显示器屏幕上每英寸面积可以放多少个像素点；苹果的PPI值高达326
{% asset_img pixel.png This is an example image %}
像素堆积成图片，所以像素本身需要颜色；如上那副图；每个像素点用一个数字来代表颜色，人眼的视锥细胞有三种分别过滤红蓝绿，其他颜色按照比例刺激；所以任何一种颜色可以通过R(红色), G(绿色),B(蓝色)按照一定的比例调配出来；这三种颜色被称为三原色；
而比例：是R,G,B的取值，分别从0-255，即8bit表示，所以一个像素点用3*8bit 即3个字节表示；而可以代表的颜色在256*256*256种；任何颜色，都可以用这三个值的组合表示；现在可以用画图试试；我们常说的RGB24就是3*8bit的形式；而一个颜色的16进制即是RGB的16进制即如：R:01,G:02,B:03--> 010203

####  原始图像和原始视频的文件表示和格式：
+ 原始图像和原始视频：
   一个原始的图片是RGB或YUV格式的，即每个像素点都由8*3 24bit/yuv的数据格式，决定即：Red Green Blue
  一个原始的视频也是没经过编码压缩的，每一帧都是完整的图像；
+ RGB YUV 表示和打开，修改等：
https://blog.csdn.net/leixiaohua1020/article/details/50534150
另外还有 ffmpeg对图片格式的转换，也能转换为rgb,yuv;
RGB和OpenCV,可以直接采集后用opencv调试；
RGB： 即每个像素由三个通道值组成R G B,都是8bit;
YUV:  
人们常用RGB表示三基色，而且RGB也可以表示出所有颜色。但视觉心理学研究表明，人眼主要是对光的感知，人的视觉系统对光的感知程度用亮度（luminance）和色度（chrominance）两个属性表示，也就是我们常说的YUV。Y就是亮度感知，而色度感知分为两个属性：色相（hue）和色饱和度（saturation）。色相也就是U,是由光波的峰值定义的，描述的是光的颜色；色饱和度V是光波的谱宽定义的，描述的是光的纯度。 采用YUV色度空间比采用RGB颜色空间更利于视频的压缩，也能更有效的表示彩色视频图像
https://www.jianshu.com/p/6a361e86ccd5
实践：
1） 先通过ffmpeg 将jpg或其他通用图片格式转换为 yuv或rgb ffmpeg -i 1.jpg -vcodec rawvideo -pix_fmt rgba raw1.rgb
2)   通过程序如https://blog.csdn.net/leixiaohua1020/article/details/50534150 或opencv来处理图像；
3） 用相关工具打开：https://github.com/leixiaohua1020/YUVplayer/blob/master/Release/yuvplayer.exe
验证；
+ 图像基本编码：
从RGB-->YUV-->JPEG/BMP/JPG/...
+ 视频基本编码：
{% asset_img video.png This is an example image %}
从yuv->h264
+ I,P,B帧和GOP的基本概念：其中I帧也叫关键帧，是一副完整的画面，而P帧则是记录I帧的变化（H.264中通过补偿算法根据I帧得到的差异文件），B帧类似。
 I 帧：一个可以独立解码的帧，size大
 P 帧：依赖前面的帧来解码，size小
 B 帧：依赖前后的帧来解码，size小
 GOP: 两个I帧之间的间隔，GOP = I(帧内编码帧) + B（双向预测帧） + P（前向预测帧）
其中I帧也叫关键帧，是一副完整的画面，而P帧则是记录I帧的变化（H.264中通过补偿算法根据I帧得到的差异文件），B帧类似。再简单点说，如果没有I帧，P帧和B帧也无法解码。这也很好理解，没有原始对比文件，只有差异文件是无法渲染画面的。 
GOP结构一般两个数字，如M=1，N=2。M指定I帧和P帧之间的距离，N指定两个I帧之间的距离，其他都是B帧填充。如M=1，N=2这里的例子是IDR PB I排序。
有些地方会讲IDR帧，其实就是GOP的第一个I帧，这个帧很重要，因为关于首开优化基本上都在去尽可能减小IDR帧的大小
+ 视频的几个参数和影响：
帧率：即每秒有多少帧，帧率越大，说明每秒帧数越多，即视频越流畅；若是假设一段10s的视频总帧数在200，则原本帧率为20fps,增大帧率
          到40fps会导致只需要5s就能放完，即加速了x2; 所以视频加速播放和慢速播放就是控制帧率的大小；
dts：DTS：Decode Time Stamp。DTS主要是标识读入内存中的bit流在什么时候开始送入解码器中进行解码。
DTS主要用于视频的解码,在解码阶段使用,每帧都有一个dts值，一般是个数值，一般视频帧之间差30，音频帧之间差20
pts:PTS主要用于视频的同步和输出.在display的时候使用.在没有B frame的情况下.DTS和PTS的输出顺序是一样的.
音视频同步的概念： 一般在看视频画面时，音频也要跟上嘴型和情节，所以音画同步需要借助dts/pts; 线性传递时，一般是一个音频帧一个视频帧；
             而音频帧和视频帧的dts也是有序的，如：a1:123 v1: 134 a2: 145 v2: 155
