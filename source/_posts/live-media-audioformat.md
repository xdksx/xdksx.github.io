---
title: live_media_audioformat
date: 2021-02-18 03:49:29
tags: audio
categories: audio
---

### 音频编码： aac, adts, wav ,mp3 等编码的意义和基本概念
+ 原始音频： 采集后得到的是音频的裸数据：在采集时需要指定采样率，量化位数(一般采样也会有几种协议，比如常见的PCM，里面会自带量化位数指定)，channle数，以及必要的大小端数据等<!--more-->
+ 音频的裸数据有以下特点，在用Audacity导入原始数据播放时，需要填写相关参数(采样率，量化协议，channel数，数据的大小端情况等)：
由此可以知道，在播放裸数据(解释)裸音频数据时，至少需要上面的几个参数；

+  音频编码在音频裸数据的基础上做了什么？可以用来干嘛?
那么对于音频编码来说，主要是在裸数据上做了封装，带了以下几件事：
1）加上音频编码的头：主要内容是采样率，channel数，量化协议，大小端等，用来告诉解码器如何解释这个音频；
2)  加上其他的元数据：比如音频编码本身的协议标志，版本号，等等
3)  带上裸数据，长度size等，有的音频编码会对裸数据进行合理的压缩，去噪等等，减少文件大小等，如opus；

+ 常见的音频编码：AAC,OPUS,FLAC,MP3,SBC,Vorbis等，更多可以看wiki:
https://zh.wikipedia.org/wiki/%E9%9F%B3%E9%A2%91%E7%BC%96%E7%A0%81%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%AF%94%E8%BE%83

+ 如何查看音频编码：最直接的就是用notepad++ ,vim等二进制方式打开，然后对着协议标志看等；
或者根据文件名使用工具查看；用播放软件查看文件信息看编码格式；但是只能看元信息；

+ 查看AAC:
AAC Audio ES Viewer 
### 音频编码文件容器：
+ 音频为什么需要容器：
如果说编码主要是压缩和携带解析的元数据，那容器的出现，除了增加更多元数据信息外，还加了时间戳dts等信息，封装为容器，一个重要的因素是为了和视频封装在一起，音视频
做同步解码播放；
+ 音频编码和容器的关系
   音频容器是在音频编码的基础上增加了一些信息，和编码格式不同，比如opus编码的容器格式是oggs，是在opus封装为一页一页，并且加了页头；
   大部分容器其实可以封装视频和音频；比如Oggs也可以封装视频，只是现在不流行；所以你看到的Oggs基本都是音频的；而纯音频容器：如wav,mp3等
+ 音视频容器常见: flv，avi,mov,mp4,3gp等
### 音频编码流媒体: 比如aac是怎么在直播系统中传输的；
流媒体是在网络传输中流式媒体数据，在网络中传输音视频数据时，也是主要是压缩的数据，比如音频，在网络上传输以opus的流格式，其实可以是oggs封装再加到其他传输协议中；
或者是Opus直接封装到完善的协议比如Rtp中；
而流媒体考虑到带宽利用率等，往往不会传输太多多余的东西，所以一些头带了的信息就不会重复封装头；
总的理解就是： 流媒体传输中，使用适合于音视频传输的(比如专门做了网络优化)的网络协议如Srt,Rtmp等，封装流媒体编码或容器进行传输；
